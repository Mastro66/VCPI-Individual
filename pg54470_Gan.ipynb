{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploração de GANs para Transferência de Estilo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Introdução\n",
    "Este projeto pretende explorar Redes Adversárias Generativas (GANs) para a transferência de estilo de imagens. O objetivo é transformar imagens de Pokémon no estilo de pinturas de artistas famosos, como Van Gogh. Este trabalho baseia-se em métodos como CycleGAN.\n",
    "Este projeto usou NVIDIA CUDA, através do PC, sem recurso a Google Colab. A gráfica utilizada foi uma NVIDIA GEFORCE GTX 1650 ti.\n",
    "\n",
    "## 2. Imports necessários\n",
    "Uma vez que nas aulas usamos pyTorch, o trabalho foi desenvolvido usando essa biblioteca.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preparação do Dataset\n",
    "Nesta secção, descreve-se a preparação dos datasets, que incluem imagens de Pokémon e pinturas de Van Gogh.\n",
    "\n",
    "### 3.1 Diretórios das Imagens\n",
    "Definem-se os caminhos para os diretórios onde se encontram as imagens de Pokémon e Van Gogh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pokemon_directory = 'C:/Users/ferna/OneDrive/Ambiente de Trabalho/4 ano 2 sem/CG/Visão por Computador e Processamento Imagem/Visão por computador/VCPI_Individual/Pokemon/pokemon/pokemon/all_images'\n",
    "van_gogh_directory = 'C:/Users/ferna/OneDrive/Ambiente de Trabalho/4 ano 2 sem/CG/Visão por Computador e Processamento Imagem/Visão por computador/VCPI_Individual/VincentVanGogh/VincentVanGogh/Saint Remy'\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, root_pokemon, root_painter, transform=None, limit=None):\n",
    "        self.transform = transform\n",
    "        self.files_pokemon = [os.path.join(root_pokemon, f) for f in os.listdir(root_pokemon) if f.endswith(('.png', '.jpg'))][:limit]\n",
    "        self.files_painter = [os.path.join(root_painter, f) for f in os.listdir(root_painter) if f.endswith(('.png', '.jpg'))]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        item_pokemon = self.transform(Image.open(self.files_pokemon[index % len(self.files_pokemon)]).convert('RGB'))\n",
    "        item_painter = self.transform(Image.open(self.files_painter[index % len(self.files_painter)]).convert('RGB'))\n",
    "        return {'A': item_pokemon, 'B': item_painter}\n",
    "\n",
    "    def __len__(self):\n",
    "        return max(len(self.files_pokemon), len(self.files_painter))\n",
    "\n",
    "# Limitar a 100 imagens de Pokémon\n",
    "pokemon_limit = 100\n",
    "dataloader_van_gogh = DataLoader(ImageDataset(pokemon_directory, van_gogh_directory, transform=transform, limit=pokemon_limit), batch_size=1, shuffle=True, num_workers=0)\n",
    "dataloader_monet = DataLoader(ImageDataset(pokemon_directory, monet_directory, transform=transform, limit=pokemon_limit), batch_size=1, shuffle=True, num_workers=0)\n",
    "\n",
    "# Visualizar exemplos\n",
    "for i, batch in enumerate(itertools.islice(dataloader_van_gogh, 3)):\n",
    "\tplt.figure(figsize=(10, 5))\n",
    "\tplt.subplot(1, 2, 1)\n",
    "\tplt.title('Van Gogh')\n",
    "\tplt.imshow(batch['B'][0].permute(1, 2, 0))\n",
    "\tplt.axis('off')\n",
    "\tplt.subplot(1, 2, 2)\n",
    "\tplt.title('Pokémon')\n",
    "\tplt.imshow(batch['A'][0].permute(1, 2, 0))\n",
    "\tplt.axis('off')\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Transformações e Augmentação de Dados\n",
    "As imagens são redimensionadas, transformadas em tensor e normalizadas. Adicionalmente, aplica-se um flip horizontal aleatório para aumentar a variedade dos dados de treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformações com Data Augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Classe de Dataset Personalizada\n",
    "Define-se uma classe de dataset personalizada para carregar as imagens de Pokémon e Van Gogh, limitando o número de imagens de Pokémon a 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, root_pokemon, root_painter, transform=None, limit=None):\n",
    "        self.transform = transform\n",
    "        self.files_pokemon = [os.path.join(root_pokemon, f) for f in os.listdir(root_pokemon) if f.endswith(('.png', '.jpg'))][:limit]\n",
    "        self.files_painter = [os.path.join(root_painter, f) for f in os.listdir(root_painter) if f.endswith(('.png', '.jpg'))]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        item_pokemon = self.transform(Image.open(self.files_pokemon[index % len(self.files_pokemon)]).convert('RGB'))\n",
    "        item_painter = self.transform(Image.open(self.files_painter[index % len(self.files_painter)]).convert('RGB'))\n",
    "        return {'A': item_pokemon, 'B': item_painter}\n",
    "\n",
    "    def __len__(self):\n",
    "        return max(len(self.files_pokemon), len(self.files_painter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Criação dos DataLoaders\n",
    "Os DataLoaders são criados para carregar as imagens durante o treino, garantindo que são embaralhadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pokemon_limit = 100\n",
    "dataloader = DataLoader(ImageDataset(pokemon_directory, van_gogh_directory, transform=transform, limit=pokemon_limit), batch_size=1, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Arquitetura dos modelos\n",
    "Nesta secção, detalha-se a arquitetura das redes geradoras e discriminadoras utilizadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Gerador\n",
    "O gerador transforma uma imagem de um domínio para outro, neste caso, de Pokémon para um estilo de pintura. A arquitetura do gerador é composta por uma camada inicial de convolução, seguida por camadas de downsampling, blocos residuais, camadas de upsampling e uma camada de saída."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_nc, output_nc):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        # Bloco de convolução inicial\n",
    "        model = [\n",
    "            nn.Conv2d(input_nc, 64, kernel_size=7, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        ]\n",
    "\n",
    "        # Downsampling\n",
    "        in_features = 64\n",
    "        out_features = in_features * 2\n",
    "        for _ in range(2):\n",
    "            model += [\n",
    "                nn.Conv2d(in_features, out_features, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(out_features),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ]\n",
    "            in_features = out_features\n",
    "            out_features = in_features * 2\n",
    "\n",
    "        # Blocos residuais\n",
    "        for _ in range(6):\n",
    "            model += [\n",
    "                nn.Conv2d(in_features, in_features, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(in_features),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ]\n",
    "\n",
    "        # Upsampling\n",
    "        out_features = in_features // 2\n",
    "        for _ in range(2):\n",
    "            model += [\n",
    "                nn.ConvTranspose2d(in_features, out_features, kernel_size=3, stride=2, padding=1, output_padding=1, bias=False),\n",
    "                nn.BatchNorm2d(out_features),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ]\n",
    "            in_features = out_features\n",
    "            out_features = in_features // 2\n",
    "\n",
    "        # Camada de saída\n",
    "        model += [nn.Conv2d(64, output_nc, kernel_size=7, padding=3), nn.Tanh()]\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Discriminador\n",
    "O discriminador distingue entre imagens reais e geradas. A arquitetura do discriminador é composta por várias camadas de convolução que reduzem progressivamente a dimensão da imagem, até uma camada final que produz um mapa de probabilidade indicando se as regiões da imagem são reais ou falsas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_nc):\n",
    "        super(Discriminator, self).__init__()\n",
    "        model = [\n",
    "            nn.Conv2d(input_nc, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        ]\n",
    "        in_features = 64\n",
    "        out_features = in_features * 2\n",
    "        for _ in range(3):\n",
    "            model += [\n",
    "                nn.Conv2d(in_features, out_features, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(out_features),\n",
    "                nn.LeakyReLU(0.2, inplace=True)\n",
    "            ]\n",
    "            in_features = out_features\n",
    "            out_features = in_features * 2\n",
    "        model += [nn.Conv2d(in_features, 1, kernel_size=4, stride=1, padding=1, bias=False)]\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Inicialização e Treino do Modelo\n",
    "Nesta secção, inicializam-se e treinam-se os modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Inicialização dos Pesos\n",
    "Inicializam-se os pesos das redes para garantir uma distribuição normal. Esta técnica é importante para assegurar que os pesos começam com valores que permitem ao modelo aprender de forma eficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Definição das Funções de Perda\n",
    "Utilizam-se três funções de perda diferentes:\n",
    "\n",
    "- criterion_GAN: Mede a diferença entre as previsões do discriminador para imagens reais e geradas, usando Mean Squared Error (MSE).\n",
    "- criterion_cycle: Calcula a diferença entre a imagem original e a imagem reconstruída após passar pelo gerador de ida e volta, utilizando L1 Loss. Esta perda garante que a imagem reconstruída seja semelhante à original.\n",
    "- criterion_identity: Verifica se o gerador mantém a identidade da imagem quando a imagem de destino é fornecida como entrada, utilizando L1 Loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_GAN = nn.MSELoss().to(device)\n",
    "criterion_cycle = nn.L1Loss().to(device)\n",
    "criterion_identity = nn.L1Loss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Inicialização dos Modelos e Otimizadores\n",
    "Inicializam-se os modelos e otimizadores necessários para o treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG_A2B = Generator(input_nc=3, output_nc=3).to(device)\n",
    "netG_B2A = Generator(input_nc=3, output_nc=3).to(device)\n",
    "netD_A = Discriminator(input_nc=3).to(device)\n",
    "netD_B = Discriminator(input_nc=3).to(device)\n",
    "\n",
    "netG_A2B.apply(weights_init_normal)\n",
    "netG_B2A.apply(weights_init_normal)\n",
    "netD_A.apply(weights_init_normal)\n",
    "netD_B.apply(weights_init_normal)\n",
    "\n",
    "optimizer_G = optim.Adam(itertools.chain(netG_A2B.parameters(), netG_B2A.parameters()), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizer_D_A = optim.Adam(netD_A.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizer_D_B = optim.Adam(netD_B.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "scheduler_G = optim.lr_scheduler.StepLR(optimizer_G, step_size=100, gamma=0.5)\n",
    "scheduler_D_A = optim.lr_scheduler.StepLR(optimizer_D_A, step_size=100, gamma=0.5)\n",
    "scheduler_D_B = optim.lr_scheduler.StepLR(optimizer_D_B, step_size=100, gamma=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Ciclo de Treino\n",
    "Nesta secção, descreve-se o ciclo de treino do modelo. Cada época envolve os seguintes passos:\n",
    "\n",
    "1. Geradores: Atualizam-se os geradores para gerar imagens que enganam os discriminadores.\n",
    "\n",
    "- Identidade: A imagem gerada a partir da imagem de destino deve ser igual à própria imagem de destino.\n",
    "- Adversarial: A imagem gerada deve ser classificada como real pelo discriminador.\n",
    "- Ciclo: A imagem original deve ser recuperada após passar pelos dois geradores (ciclo de ida e volta).\n",
    "\n",
    "2. Discriminadores: Atualizam-se os discriminadores para distinguir entre imagens reais e geradas.\n",
    "\n",
    "- A imagem real deve ser classificada como real.\n",
    "- A imagem gerada deve ser classificada como falsa.\n",
    "3. Atualização dos Otimizadores: Os otimizadores são atualizados após o cálculo das perdas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(epoch, dataloader, netG_A2B, netG_B2A, netD_A, netD_B, optimizer_G, optimizer_D_A, optimizer_D_B, criterion_GAN, criterion_cycle, criterion_identity, device):\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        real_A = batch['A'].to(device)\n",
    "        real_B = batch['B'].to(device)\n",
    "\n",
    "        valid = torch.ones((real_A.size(0), *netD_A(real_A).shape[1:]), requires_grad=False).to(device)\n",
    "        fake = torch.zeros((real_A.size(0), *netD_A(real_A).shape[1:]), requires_grad=False).to(device)\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        loss_id_A = criterion_identity(netG_B2A(real_A), real_A) * 5.0\n",
    "        loss_id_B = criterion_identity(netG_A2B(real_B), real_B) * 5.0\n",
    "\n",
    "        fake_B = netG_A2B(real_A)\n",
    "        loss_GAN_A2B = criterion_GAN(netD_B(fake_B), valid)\n",
    "        fake_A = netG_B2A(real_B)\n",
    "        loss_GAN_B2A = criterion_GAN(netD_A(fake_A), valid)\n",
    "\n",
    "        rec_A = netG_B2A(fake_B)\n",
    "        loss_cycle_A = criterion_cycle(rec_A, real_A) * 10.0\n",
    "        rec_B = netG_A2B(fake_A)\n",
    "        loss_cycle_B = criterion_cycle(rec_B, real_B) * 10.0\n",
    "\n",
    "        loss_G = loss_id_A + loss_id_B + loss_GAN_A2B + loss_GAN_B2A + loss_cycle_A + loss_cycle_B\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        optimizer_D_A.zero_grad()\n",
    "        loss_real_A = criterion_GAN(netD_A(real_A), valid)\n",
    "        loss_fake_A = criterion_GAN(netD_A(fake_A.detach()), fake)\n",
    "        loss_D_A = (loss_real_A + loss_fake_A) * 0.5\n",
    "        loss_D_A.backward()\n",
    "        optimizer_D_A.step()\n",
    "\n",
    "        optimizer_D_B.zero_grad()\n",
    "        loss_real_B = criterion_GAN(netD_B(real_B), valid)\n",
    "        loss_fake_B = criterion_GAN(netD_B(fake_B.detach()), fake)\n",
    "        loss_D_B = (loss_real_B + loss_fake_B) * 0.5\n",
    "        loss_D_B.backward()\n",
    "        optimizer_D_B.step()\n",
    "\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(dataloader)}], '\n",
    "                  f'Loss D_A: {loss_D_A.item():.4f}, Loss D_B: {loss_D_B.item():.4f}, '\n",
    "                  f'Loss G: {loss_G.item():.4f}')\n",
    "\n",
    "    scheduler_G.step()\n",
    "    scheduler_D_A.step()\n",
    "    scheduler_D_B.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Treino Principal\n",
    "Treina-se o modelo ao longo de várias épocas utilizando o ciclo de treino definido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "dataloader = DataLoader(ImageDataset(pokemon_directory, van_gogh_directory, transform=transform, limit=pokemon_limit), batch_size=1, shuffle=True, num_workers=0)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_epoch(epoch, dataloader, netG_A2B, netG_B2A, netD_A, netD_B, optimizer_G, optimizer_D_A, optimizer_D_B, criterion_GAN, criterion_cycle, criterion_identity, device)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
